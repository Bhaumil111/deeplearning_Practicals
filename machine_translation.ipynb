{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"1. Basic code for machine translation (German -> English) using torchtext, Seq2Seq model using GRU.\n2. There is a lot of scope of improvement like better architecture, better training and addressing overfitting.\n3. You can also refer my another code which doesn't use torchtext at https://www.kaggle.com/code/priyankdl/machine-translation-seq-2-seq\n4. You can also refer my another code which uses Bahdanau Attention mechanism but doesn't use torchtext  at https://www.kaggle.com/code/priyankdl/machine-translation-seq-2-seq-bahdanau-attention","metadata":{}},{"cell_type":"code","source":"!pip install torchtext==0.15.2 torch==2.0.1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T07:12:34.647459Z","iopub.execute_input":"2025-03-26T07:12:34.648185Z","iopub.status.idle":"2025-03-26T07:14:23.412638Z","shell.execute_reply.started":"2025-03-26T07:12:34.648149Z","shell.execute_reply":"2025-03-26T07:14:23.411456Z"}},"outputs":[{"name":"stdout","text":"Collecting torchtext==0.15.2\n  Downloading torchtext-0.15.2-cp310-cp310-manylinux1_x86_64.whl.metadata (7.4 kB)\nCollecting torch==2.0.1\n  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torchtext==0.15.2) (4.66.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchtext==0.15.2) (2.32.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchtext==0.15.2) (1.26.4)\nCollecting torchdata==0.6.1 (from torchtext==0.15.2)\n  Downloading torchdata-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (3.15.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (3.1.4)\nCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.0.0 (from torch==2.0.1)\n  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (70.0.0)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.43.0)\nRequirement already satisfied: urllib3>=1.25 in /opt/conda/lib/python3.10/site-packages (from torchdata==0.6.1->torchtext==0.15.2) (1.26.18)\nCollecting cmake (from triton==2.0.0->torch==2.0.1)\n  Downloading cmake-3.31.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\nCollecting lit (from triton==2.0.0->torch==2.0.1)\n  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.0.1) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext==0.15.2) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext==0.15.2) (3.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext==0.15.2) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.0.1) (1.3.0)\nDownloading torchtext-0.15.2-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchdata-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading cmake-3.31.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.8/27.8 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, cmake, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchdata, torchtext\n  Attempting uninstall: torch\n    Found existing installation: torch 2.4.0\n    Uninstalling torch-2.4.0:\n      Successfully uninstalled torch-2.4.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npytorch-lightning 2.4.0 requires torch>=2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed cmake-3.31.6 lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 torchdata-0.6.1 torchtext-0.15.2 triton-2.0.0\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!pip install 'portalocker>=2.0.0'\n#you may require to restart the kernel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T07:12:04.816534Z","iopub.execute_input":"2025-03-26T07:12:04.816794Z","iopub.status.idle":"2025-03-26T07:12:14.323282Z","shell.execute_reply.started":"2025-03-26T07:12:04.816761Z","shell.execute_reply":"2025-03-26T07:12:14.322447Z"}},"outputs":[{"name":"stdout","text":"Collecting portalocker>=2.0.0\n  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\nDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\nInstalling collected packages: portalocker\nSuccessfully installed portalocker-3.1.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator\nfrom torchtext.datasets import multi30k, Multi30k\nfrom typing import Iterable, List\nfrom torch.nn.utils.rnn import pad_sequence\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nfrom torch.utils.data import DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T07:14:54.637088Z","iopub.execute_input":"2025-03-26T07:14:54.637446Z","iopub.status.idle":"2025-03-26T07:14:57.472171Z","shell.execute_reply.started":"2025-03-26T07:14:54.637413Z","shell.execute_reply":"2025-03-26T07:14:57.471201Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device=torch.device(type='cuda',index=0)\nelse:\n    device=torch.device(type='cpu',index=0)\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T07:14:57.473822Z","iopub.execute_input":"2025-03-26T07:14:57.474370Z","iopub.status.idle":"2025-03-26T07:14:57.518565Z","shell.execute_reply.started":"2025-03-26T07:14:57.474331Z","shell.execute_reply":"2025-03-26T07:14:57.517698Z"}},"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"\nmulti30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\nmulti30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n\nSRC_LANGUAGE = 'de' \nTGT_LANGUAGE = 'en'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T07:25:59.633850Z","iopub.execute_input":"2025-03-26T07:25:59.634230Z","iopub.status.idle":"2025-03-26T07:25:59.639045Z","shell.execute_reply.started":"2025-03-26T07:25:59.634195Z","shell.execute_reply":"2025-03-26T07:25:59.638122Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"!pip install -U torchdata\n!pip install -U spacy\n!python -m spacy download en_core_web_sm \n#run a module spacy as a script and install the small version of spaCy’s \n#English language model, allowing you to process English text using spaCy for tasks \n#like tokenization, named entity recognition, and part-of-speech tagging.\n!python -m spacy download de_core_news_sm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T07:26:39.556222Z","iopub.execute_input":"2025-03-26T07:26:39.556808Z","iopub.status.idle":"2025-03-26T07:27:13.274233Z","shell.execute_reply.started":"2025-03-26T07:26:39.556777Z","shell.execute_reply":"2025-03-26T07:27:13.273320Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchdata in /opt/conda/lib/python3.10/site-packages (0.11.0)\nRequirement already satisfied: urllib3>=1.25 in /opt/conda/lib/python3.10/site-packages (from torchdata) (1.26.18)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchdata) (2.32.3)\nRequirement already satisfied: torch>=2 in /opt/conda/lib/python3.10/site-packages (from torchdata) (2.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (3.15.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (11.7.99)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (11.7.99)\nRequirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (11.7.101)\nRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (8.5.0.96)\nRequirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (11.10.3.66)\nRequirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (10.9.0.58)\nRequirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (10.2.10.91)\nRequirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (11.4.0.1)\nRequirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (11.7.4.91)\nRequirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (2.14.3)\nRequirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (11.7.91)\nRequirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.10/site-packages (from torch>=2->torchdata) (2.0.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=2->torchdata) (70.0.0)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=2->torchdata) (0.43.0)\nRequirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch>=2->torchdata) (3.31.6)\nRequirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch>=2->torchdata) (18.1.8)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchdata) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchdata) (3.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchdata) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2->torchdata) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2->torchdata) (1.3.0)\nRequirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (3.8.4)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.4.0,>=8.3.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (8.3.4)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.12.3)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (4.66.4)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.26.4)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.9.2)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.1.4)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy) (70.0.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.4.0)\nRequirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy) (3.1.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\nRequirement already satisfied: blis<1.3.0,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.4)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy) (2.1.5)\nRequirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n\n\u001b[38;5;1m✘ No compatible package found for 'de_core_web_sm' (spaCy v3.8.4)\u001b[0m\n\nCollecting fr-core-news-sm==3.8.0\n  Using cached https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('fr_core_news_sm')\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"#setup the tokenizer for German and English\nde_tokenizer = get_tokenizer('spacy', language='de_core_news_sm')\nen_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n\n\n#function to yield list of tokens for building the vocab\ndef yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n    if language=='de':\n        for data_sample in data_iter:\n            yield de_tokenizer(data_sample[0])\n    elif language=='en':\n        for data_sample in data_iter:\n            yield en_tokenizer(data_sample[1])\n            \n# Define special symbols and indices\nUNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n# Make sure the tokens are in order of their indices to properly insert them in vocab\nspecial_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n\n#build vocab for German\ntrain_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n\n#torchtext.datasets.Multi30k(root: str = '.data', \n#split: Union[Tuple[str], str] = ('train', 'valid', 'test'), \n#language_pair: Tuple[str] = ('de', 'en')). Available options are (‘de’,’en’) and (‘en’, ‘de’)\n\n#train: 29000, #valid: 1014, #test: 1000\n\n#Returns DataPipe that yields tuple of source and target sentences (str,str)\n\nvocab_de=build_vocab_from_iterator(yield_tokens(train_iter, 'de'),\n                                                    min_freq=1,\n                                                    specials=special_symbols,\n                                                    special_first=True)\nvocab_de.set_default_index(UNK_IDX)\n\n\n#Now, build vocab for English\ntrain_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\nvocab_en=build_vocab_from_iterator(yield_tokens(train_iter, 'en'),\n                                                    min_freq=1,\n                                                    specials=special_symbols,\n                                                    special_first=True)\nvocab_en.set_default_index(UNK_IDX)","metadata":{"execution":{"iopub.status.busy":"2025-03-26T07:27:41.071091Z","iopub.execute_input":"2025-03-26T07:27:41.071418Z","iopub.status.idle":"2025-03-26T07:27:41.131109Z","shell.execute_reply.started":"2025-03-26T07:27:41.071391Z","shell.execute_reply":"2025-03-26T07:27:41.129857Z"},"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m TGT_LANGUAGE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# French\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Load tokenizers for German and French\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m de_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mget_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspacy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mde_core_news_sm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m fr_tokenizer \u001b[38;5;241m=\u001b[39m get_tokenizer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspacy\u001b[39m\u001b[38;5;124m\"\u001b[39m, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfr_core_news_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Function to yield tokens for vocabulary building\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchtext/data/utils.py:94\u001b[0m, in \u001b[0;36mget_tokenizer\u001b[0;34m(tokenizer, language)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     spacy \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m:\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# Model shortcuts no longer work in spaCy 3.0+, try using fullnames\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# List is from https://github.com/explosion/spaCy/blob/b903de3fcb56df2f7247e5b6cfa6b66f4ff02b62/spacy/errors.py#L789\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     OLD_MODEL_SHORTCUTS \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     99\u001b[0m         spacy\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mOLD_MODEL_SHORTCUTS \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(spacy\u001b[38;5;241m.\u001b[39merrors, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOLD_MODEL_SHORTCUTS\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    100\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/spacy/__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m     28\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/spacy/util.py:472\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m--> 472\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n","\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'de_core_news_sm'. It doesn't seem to be a Python package or a valid path to a data directory."],"ename":"OSError","evalue":"[E050] Can't find model 'de_core_news_sm'. It doesn't seem to be a Python package or a valid path to a data directory.","output_type":"error"}],"execution_count":17},{"cell_type":"code","source":"print(type(vocab_en))\nprint(\"English Vocab Length:\",vocab_en.__len__())\nprint(\"German Vocab Length:\",vocab_de.__len__())","metadata":{"execution":{"iopub.status.busy":"2025-03-19T11:50:37.586953Z","iopub.status.idle":"2025-03-19T11:50:37.587319Z","shell.execute_reply.started":"2025-03-19T11:50:37.587140Z","shell.execute_reply":"2025-03-19T11:50:37.587158Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#prepare separate batch for source sentence ids and target sentence ids\n#insert <EOS> in source sentence\n#insert <BOS> and <EOS> in target sentence\n#pad sentences in a batch to same length\ndef collate_fn(batch):\n    src_batch, tgt_batch = [], []\n    for src_sample, tgt_sample in batch:\n        \n        src_sample=src_sample.rstrip(\"\\n\") #string\n        tgt_sample=tgt_sample.rstrip(\"\\n\")\n        \n        src_tokens=de_tokenizer(src_sample) #sentence/string to list of word tokens\n        tgt_tokens=en_tokenizer(tgt_sample)\n        \n        src_ids=vocab_de(src_tokens) #from list of word tokens to list of ids\n        tgt_ids=vocab_en(tgt_tokens)\n        \n        src_ids.append(EOS_IDX) #append <EOS> to list\n        tgt_ids.append(EOS_IDX)\n        \n        tgt_ids.insert(0,BOS_IDX) #start with <BOS> in list\n        \n        src_tensor=torch.tensor(src_ids) #convert to tensor\n        tgt_tensor=torch.tensor(tgt_ids)\n        \n        \n        src_batch.append(src_tensor) #list of tensors\n        tgt_batch.append(tgt_tensor)\n\n    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first=True) #returns tensor\n    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX, batch_first=True)\n    return src_batch, tgt_batch","metadata":{"execution":{"iopub.status.busy":"2025-03-19T11:50:37.588982Z","iopub.status.idle":"2025-03-19T11:50:37.589334Z","shell.execute_reply.started":"2025-03-19T11:50:37.589160Z","shell.execute_reply":"2025-03-19T11:50:37.589178Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, input_size, embed_size, hidden_size, dropout_p=0.1):\n        super().__init__()\n        self.e=nn.Embedding(input_size, embed_size)\n        self.dropout=nn.Dropout(dropout_p)\n        self.gru=nn.GRU(embed_size,hidden_size, batch_first=True)\n    \n    def forward(self,x):\n        x=self.e(x)\n        x=self.dropout(x)\n        outputs, hidden=self.gru(x)\n        return outputs, hidden","metadata":{"execution":{"iopub.status.busy":"2025-03-19T11:50:37.590966Z","iopub.status.idle":"2025-03-19T11:50:37.591294Z","shell.execute_reply.started":"2025-03-19T11:50:37.591133Z","shell.execute_reply":"2025-03-19T11:50:37.591149Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self,output_size,embed_size,hidden_size):\n        super().__init__()\n        self.e=nn.Embedding(output_size,embed_size)\n        self.relu=nn.ReLU()\n        self.gru=nn.GRU(embed_size, hidden_size, batch_first=True)\n        self.lin=nn.Linear(hidden_size,output_size)\n        self.lsoftmax=nn.LogSoftmax(dim=-1)\n    \n    def forward(self,x,prev_hidden):\n        x=self.e(x)\n        x=self.relu(x)\n        output,hidden=self.gru(x,prev_hidden)\n        y=self.lin(output)\n        y=self.lsoftmax(y)\n        return y, hidden","metadata":{"execution":{"iopub.status.busy":"2025-03-19T11:50:37.592549Z","iopub.status.idle":"2025-03-19T11:50:37.592897Z","shell.execute_reply.started":"2025-03-19T11:50:37.592739Z","shell.execute_reply":"2025-03-19T11:50:37.592756Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_one_epoch():\n    encoder.train()\n    decoder.train()\n    track_loss=0\n    \n    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n    train_dataloader = DataLoader(train_iter, batch_size=batch_size, collate_fn=collate_fn)\n    \n    for i, (s_ids,t_ids) in enumerate(train_dataloader):\n        \n        s_ids=s_ids.to(device)\n        t_ids=t_ids.to(device)\n        encoder_outputs, encoder_hidden=encoder(s_ids)\n        decoder_hidden=encoder_hidden\n        yhats, decoder_hidden = decoder(t_ids[:,0:-1],decoder_hidden)\n                    \n        gt=t_ids[:,1:]\n        \n        yhats_reshaped=yhats.view(-1,yhats.shape[-1])\n        \n        gt=gt.reshape(-1)\n        \n        \n        loss=loss_fn(yhats_reshaped,gt)\n        track_loss+=loss.item()\n        \n        opte.zero_grad()\n        optd.zero_grad()\n        \n        loss.backward()\n        \n        opte.step()\n        optd.step()\n        \n    return track_loss/(i+1)\n    ","metadata":{"execution":{"iopub.status.busy":"2025-03-19T11:50:37.593884Z","iopub.status.idle":"2025-03-19T11:50:37.594208Z","shell.execute_reply.started":"2025-03-19T11:50:37.594051Z","shell.execute_reply":"2025-03-19T11:50:37.594067Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#eval loop (written assuming batch_size=1)\ndef eval_one_epoch(e,n_epochs):\n    encoder.eval()\n    decoder.eval()\n    track_loss=0\n    \n    val_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n    val_dataloader = DataLoader(val_iter, batch_size=1, collate_fn=collate_fn)\n    \n    with torch.no_grad():\n        for i, (s_ids,t_ids) in enumerate(val_dataloader):\n            s_ids=s_ids.to(device) # [1, source sequence length]\n            t_ids=t_ids.to(device)\n            encoder_outputs, encoder_hidden=encoder(s_ids)\n            decoder_hidden=encoder_hidden #n_dim=3\n            input_id=t_ids[:,0] #shape is just [1]\n            yhats=[]\n            if e+1==n_epochs:\n                pred_sentence=\"\"\n            for j in range(1,t_ids.shape[1]): #j starts from 1 #iterates for len(t_ids)-1 times as the last id is of <EOS>\n                probs, decoder_hidden = decoder(input_id.unsqueeze(1),decoder_hidden) #need batch_size x seq_length\n                yhats.append(probs)\n                _,input_id=torch.topk(probs,1,dim=-1)\n                input_id=input_id.squeeze(1,2) #still a tensor\n                if e+1==n_epochs:                    \n                    word=vocab_en.lookup_token(input_id.item()) #batch_size=1\n                    pred_sentence+=word + \" \"\n                if input_id.item() == 3: #batch_size=1 #Id 3 is <EOS>\n                    break\n                                \n            if e+1==n_epochs:\n                src_sentence_tokens=vocab_de.lookup_tokens(s_ids.tolist()[0])\n                src_sentence=\" \".join(src_sentence_tokens)\n                gt_sentence_tokens=vocab_en.lookup_tokens(t_ids[:,1:].tolist()[0])\n                gt_sentence=\" \".join(gt_sentence_tokens)\n                print(\"\\n-----------------------------------\")\n                print(\"Source Sentence:\",src_sentence)\n                print(\"GT Sentence:\",gt_sentence)\n                print(\"Predicted Sentence:\",pred_sentence)\n            \n            yhats_cat=torch.cat(yhats,dim=1)\n            yhats_reshaped=yhats_cat.view(-1,yhats_cat.shape[-1])\n            gt=t_ids[:,1:j+1] #shape is [1, target sequence length -1] #as <BOS> is not part of GT\n            \n            gt=gt.view(-1) #shape is [target sequence length -1]\n            \n            loss=loss_fn(yhats_reshaped,gt)\n            track_loss+=loss.item()\n            \n        if e+1==n_epochs:    \n            print(\"-----------------------------------\")\n        return track_loss/(i+1)   ","metadata":{"execution":{"iopub.status.busy":"2025-03-19T11:50:37.595826Z","iopub.status.idle":"2025-03-19T11:50:37.596174Z","shell.execute_reply.started":"2025-03-19T11:50:37.596007Z","shell.execute_reply":"2025-03-19T11:50:37.596025Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"embed_size=300\nhidden_size=512\nbatch_size=32\n\nencoder=Encoder(vocab_de.__len__(),embed_size,hidden_size).to(device) #translation-direction sensitive\ndecoder=Decoder(vocab_en.__len__(),embed_size,hidden_size).to(device) #translation-direction sensitive\n\nloss_fn=nn.NLLLoss(ignore_index=1).to(device)\nlr=0.001\nopte=optim.Adam(params=encoder.parameters(), lr=lr, weight_decay=0.001)\noptd=optim.Adam(params=decoder.parameters(), lr=lr, weight_decay=0.001)\n\nn_epochs=5\n\nfor e in range(n_epochs):\n    print(\"Epoch=\",e+1, sep=\"\", end=\", \")\n    print(\"Train Loss=\", round(train_one_epoch(),4), sep=\"\", end=\", \")\n    print(\"Eval Loss=\",round(eval_one_epoch(e,n_epochs),4), sep=\"\")","metadata":{"execution":{"iopub.status.busy":"2025-03-19T11:50:37.597124Z","iopub.status.idle":"2025-03-19T11:50:37.597456Z","shell.execute_reply.started":"2025-03-19T11:50:37.597294Z","shell.execute_reply":"2025-03-19T11:50:37.597311Z"},"trusted":true},"outputs":[],"execution_count":null}]}